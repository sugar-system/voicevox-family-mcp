// Polyfill a minimal global 'window' for Node.js (do this before any other imports)
const _window = {
  location: {
    protocol: 'http:',
    hostname: 'localhost',
    port: '10101',
    href: 'http://localhost:10101/',
  },
};

if (typeof global.window === 'undefined') {
  global.window = _window as unknown as Window & typeof globalThis;
}

import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { z } from 'zod';
import axios from 'axios';
import { VoiceSynthesisService } from '../api/voiceSynthesisService';
import type { AudioQuery } from '../api/schema/AudioQuery';

/**
 * MCPã‚µãƒ¼ãƒãƒ¼ã®è¨­å®š
 */
interface McpServerConfig {
  engineUrl: string;
  engineType: 'aivis' | 'voicevox';
  serverName: string;
  serverVersion: string;
}

/**
 * MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
 */
interface SpeakRequestParams {
  text: string;
  language: string;
  speaker_id: number;
  model_id: number;
  assist_text_weight: number;
  auto_split: boolean;
  length: number;
  noise: number;
  noisew: number;
  sd_ratio: number;
  split_interval: number;
  style: string;
  style_weight: number;
}

/**
 * éŸ³å£°åˆæˆã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
 */
interface IVoiceSynthesisService {
  createAudioQuery(params: { text: string; speaker: number }): Promise<AudioQuery>;
  synthesizeSpeech(params: { speaker: number; query: AudioQuery }): Promise<Buffer>;
  playAudio(audioData: Buffer): Promise<void>;
}

/**
 * éŸ³å£°åˆæˆMCPã‚µãƒ¼ãƒãƒ¼ã‚¯ãƒ©ã‚¹
 */
export class VoiceMcpServer {
  private mcp: McpServer;
  private voiceService: IVoiceSynthesisService;
  private config: McpServerConfig;

  constructor(config: McpServerConfig, voiceService: IVoiceSynthesisService) {
    this.config = config;
    this.voiceService = voiceService;

    this.mcp = new McpServer({
      name: config.serverName,
      version: config.serverVersion,
    });

    this.setupTools();
  }

  /**
   * MCPãƒ„ãƒ¼ãƒ«ã‚’è¨­å®šã™ã‚‹
   */
  private setupTools(): void {
    // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è©±è€…IDã®è¨­å®šï¼ˆã‚¨ãƒ³ã‚¸ãƒ³ã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦ç•°ãªã‚‹ï¼‰
    // Aivis Speech
    // Anneli - ãƒãƒ¼ãƒãƒ«: 888753760
    // Anneli - é€šå¸¸: 888753761
    // Anneli - ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é«˜ã‚: 888753762
    // Anneli - è½ã¡ç€ã: 888753763
    // Anneli - ä¸Šæ©Ÿå«Œ: 888753764
    // Anneli - æ€’ã‚Šãƒ»æ‚²ã—ã¿: 888753765
    // white - ãƒãƒ¼ãƒãƒ«: 706073888
    //
    // VOICEVOX
    // å››å›½ã‚ãŸã‚“ï¼ˆã‚ã¾ã‚ã¾ï¼‰: 0
    // ãšã‚“ã ã‚‚ã‚“ï¼ˆã‚ã¾ã‚ã¾ï¼‰: 1
    // æ˜¥æ—¥éƒ¨ã¤ã‚€ãï¼ˆãƒãƒ¼ãƒãƒ«ï¼‰: 8
    const defaultSpeakerId = this.config.engineType === 'aivis' ? 888753760 : 1;

    this.mcp.tool(
      'speak_response',
      {
        text: z.string(),
        style: z.string().default('Neutral'),
        language: z.string().default('JP'),
        speaker_id: z.number().default(defaultSpeakerId),
        model_id: z.number().default(0),
        style_weight: z.number().default(1.0),
        sd_ratio: z.number().default(0.2),
        noise: z.number().default(0.6),
        noisew: z.number().default(0.8),
        length: z.number().default(1.0),
        auto_split: z.boolean().default(false),
        split_interval: z.number().default(0.5),
        assist_text_weight: z.number().default(1.0),
      },
      async (params: SpeakRequestParams) => {
        try {
          console.error(`Converting to speech: "${params.text}" with speaker ${params.speaker_id}`);
          console.error(`Using engine: ${this.config.engineType} at ${this.config.engineUrl}`);

          // ã‚¹ãƒ†ãƒƒãƒ—1: AudioQueryã‚’ä½œæˆ
          const audioQuery = await this.voiceService.createAudioQuery({
            text: params.text,
            speaker: params.speaker_id,
          });

          // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
          audioQuery.intonationScale = params.style_weight;
          audioQuery.speedScale = params.length; // lengthã‚’speedScaleã«å¤‰æ›
          audioQuery.volumeScale = 1.0; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŸ³é‡

          // kanaãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«èª­ã¿ä¸Šã’ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
          // (ã“ã‚Œã¯ã‚¨ãƒ³ã‚¸ãƒ³ã”ã¨ã«å°‘ã—æŒ™å‹•ãŒç•°ãªã‚‹ãŒã€å¤§ä½“å•é¡Œãªã„)
          audioQuery.kana = params.text;

          // ã‚¹ãƒ†ãƒƒãƒ—2: éŸ³å£°åˆæˆ
          const audioData = await this.voiceService.synthesizeSpeech({
            speaker: params.speaker_id,
            query: audioQuery,
          });

          // éŸ³å£°ã‚’å†ç”Ÿ
          await this.voiceService.playAudio(audioData);

          return {
            content: [
              {
                type: 'text',
                text: `Successfully spoke: "${params.text}" with speaker ID ${params.speaker_id} using ${this.config.engineType}`,
              },
            ],
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : 'Unknown error';
          console.error('TTS Error:', errorMessage);
          if (axios.isAxiosError(error) && error.response) {
            console.error('API Response Status:', error.response.status);
            console.error('API Response Data:', error.response.data);
          }
          throw new Error(`TTS failed: ${errorMessage}`);
        }
      },
    );
  }

  /**
   * ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
   * @param config ã‚µãƒ¼ãƒãƒ¼è¨­å®š
   * @returns VoiceMcpServerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
   */
  static create(config: McpServerConfig): VoiceMcpServer {
    const voiceService = VoiceSynthesisService.create(config.engineUrl);
    return new VoiceMcpServer(config, voiceService);
  }

  /**
   * ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã™ã‚‹
   */
  public async start(): Promise<void> {
    const transport = new StdioServerTransport();
    await this.mcp.connect(transport);
    console.error(
      `âœ… MCP Server "${this.config.serverName}" v${this.config.serverVersion} started`,
    );
    console.error(`ğŸ”Œ Connected to ${this.config.engineType} engine at: ${this.config.engineUrl}`);
  }
}
